{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-14T15:35:55.402077900Z",
     "start_time": "2023-05-14T15:35:55.360586600Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset manipulation\n",
    "import pandas as pd\n",
    "# numerical operations\n",
    "import numpy as np\n",
    "# graphing applications\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Dataset](https://www.kaggle.com/datasets/utkarshx27/smoking-dataset-from-uk) (link to dataset)\n",
    "\n",
    "This dataset consists of smoking data gathered from the uk, and contains lots of demographic data along with the type of tobacco consumed, this is my first foray into categorical variables in quite some time, so this will be a good welcoming back. I am planning on selecting my target variable as the `smoke` column which contains a **1** if they are currently a smoker and a **0** if they are not. I will use all the features left after removing that column as my feature space. I may involve feature engineering in the analysis which will help me decide which features to keep and which ones to remove. This is my second health dataset in a row, and I am interested in the trends, as I have a smoker in my family."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "outputs": [
    {
     "data": {
      "text/plain": "   gender  age marital_status highest_qualification nationality ethnicity  \\\n1    Male   38       Divorced      No Qualification     British     White   \n2  Female   42         Single      No Qualification     British     White   \n3    Male   40        Married                Degree     English     White   \n4  Female   40        Married                Degree     English     White   \n5  Female   39        Married          GCSE/O Level     British     White   \n\n       gross_income     region smoke  amt_weekends  amt_weekdays     type  \n1    2,600 to 5,200  The North    No           NaN           NaN      NaN  \n2       Under 2,600  The North   Yes          12.0          12.0  Packets  \n3  28,600 to 36,400  The North    No           NaN           NaN      NaN  \n4  10,400 to 15,600  The North    No           NaN           NaN      NaN  \n5    2,600 to 5,200  The North    No           NaN           NaN      NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gender</th>\n      <th>age</th>\n      <th>marital_status</th>\n      <th>highest_qualification</th>\n      <th>nationality</th>\n      <th>ethnicity</th>\n      <th>gross_income</th>\n      <th>region</th>\n      <th>smoke</th>\n      <th>amt_weekends</th>\n      <th>amt_weekdays</th>\n      <th>type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>Male</td>\n      <td>38</td>\n      <td>Divorced</td>\n      <td>No Qualification</td>\n      <td>British</td>\n      <td>White</td>\n      <td>2,600 to 5,200</td>\n      <td>The North</td>\n      <td>No</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Female</td>\n      <td>42</td>\n      <td>Single</td>\n      <td>No Qualification</td>\n      <td>British</td>\n      <td>White</td>\n      <td>Under 2,600</td>\n      <td>The North</td>\n      <td>Yes</td>\n      <td>12.0</td>\n      <td>12.0</td>\n      <td>Packets</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Male</td>\n      <td>40</td>\n      <td>Married</td>\n      <td>Degree</td>\n      <td>English</td>\n      <td>White</td>\n      <td>28,600 to 36,400</td>\n      <td>The North</td>\n      <td>No</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Female</td>\n      <td>40</td>\n      <td>Married</td>\n      <td>Degree</td>\n      <td>English</td>\n      <td>White</td>\n      <td>10,400 to 15,600</td>\n      <td>The North</td>\n      <td>No</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Female</td>\n      <td>39</td>\n      <td>Married</td>\n      <td>GCSE/O Level</td>\n      <td>British</td>\n      <td>White</td>\n      <td>2,600 to 5,200</td>\n      <td>The North</td>\n      <td>No</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## loading in dataset\n",
    "smoking_df = pd.read_csv('smoking.csv', index_col=0)\n",
    "\n",
    "smoking_df.head()  # Looks like we have some missing values as well, interesting!"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T15:35:55.450077700Z",
     "start_time": "2023-05-14T15:35:55.374069200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "outputs": [
    {
     "data": {
      "text/plain": "gender                    object\nage                        int64\nmarital_status            object\nhighest_qualification     object\nnationality               object\nethnicity                 object\ngross_income              object\nregion                    object\nsmoke                     object\namt_weekends             float64\namt_weekdays             float64\ntype                      object\ndtype: object"
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smoking_df.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T15:35:55.459578100Z",
     "start_time": "2023-05-14T15:35:55.389568800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ase you can see, we have quite a lot of categorical variables to handle (most of the dataset), so first let's get to encoding them, but before we do that, let's analyze and see if any columns contain NaN values. That is our first worry."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "outputs": [
    {
     "data": {
      "text/plain": "{'gender': False,\n 'age': False,\n 'marital_status': False,\n 'highest_qualification': False,\n 'nationality': False,\n 'ethnicity': False,\n 'gross_income': False,\n 'region': False,\n 'smoke': False,\n 'amt_weekends': True,\n 'amt_weekdays': True,\n 'type': True}"
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contains_nan = {}\n",
    "\n",
    "for each_column in smoking_df.columns:\n",
    "    contains_nan[each_column] = smoking_df[each_column].hasnans\n",
    "\n",
    "contains_nan"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T15:35:55.460078100Z",
     "start_time": "2023-05-14T15:35:55.404577800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "So, it looks like we have about 3 columns that contain NaN values, that is the first part of the dataset we want to fix, after that, we can begin tackling the categorical variables!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have one small issue though, one of the NaN columns contains categorical data, not numerical data, so we may have to use frequency to fill those values.\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "type_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "type_imputer.fit(smoking_df[['type']])\n",
    "\n",
    "values = type_imputer.transform(smoking_df[['type']])\n",
    "\n",
    "type_imputed_smoking_df = smoking_df.copy()\n",
    "\n",
    "type_imputed_smoking_df['type'] = values\n",
    "\n",
    "type_imputed_smoking_df[\n",
    "    'type'].hasnans  # Yay! The missing values have been removed, now we can move onto the other 2 numerical columns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T15:35:55.460078100Z",
     "start_time": "2023-05-14T15:35:55.419577900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the same thing for amt_weekdays, except use the `mean` strategy to impute the missing values\n",
    "\n",
    "amt_weekdays_imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "amt_weekdays_imputer.fit(smoking_df[['amt_weekdays']])\n",
    "\n",
    "values = amt_weekdays_imputer.transform(smoking_df[['amt_weekdays']])\n",
    "\n",
    "amt_weekdays_imputed_smoking_df = type_imputed_smoking_df.copy()\n",
    "\n",
    "amt_weekdays_imputed_smoking_df['amt_weekdays'] = values\n",
    "\n",
    "amt_weekdays_imputed_smoking_df['amt_weekdays'].hasnans"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T15:35:55.460577900Z",
     "start_time": "2023-05-14T15:35:55.436078Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the same thing for the amt_weekends, except use the `mean` strategy to impute the missing values\n",
    "\n",
    "amt_weekends_imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "amt_weekends_imputer.fit(smoking_df[['amt_weekends']])\n",
    "\n",
    "values = amt_weekends_imputer.transform(smoking_df[['amt_weekends']])\n",
    "\n",
    "amt_weekends_imputed_smoking_df = amt_weekdays_imputed_smoking_df.copy()\n",
    "\n",
    "amt_weekends_imputed_smoking_df['amt_weekends'] = values\n",
    "\n",
    "amt_weekends_imputed_smoking_df['amt_weekends'].hasnans"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T15:35:55.466078100Z",
     "start_time": "2023-05-14T15:35:55.451077800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "outputs": [
    {
     "data": {
      "text/plain": "{'gender': False,\n 'age': False,\n 'marital_status': False,\n 'highest_qualification': False,\n 'nationality': False,\n 'ethnicity': False,\n 'gross_income': False,\n 'region': False,\n 'smoke': False,\n 'amt_weekends': False,\n 'amt_weekdays': False,\n 'type': False}"
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_smoking_df = amt_weekends_imputed_smoking_df.copy()\n",
    "\n",
    "contains_nan = {}\n",
    "\n",
    "for each_column in imputed_smoking_df.columns:\n",
    "    contains_nan[each_column] = imputed_smoking_df[each_column].hasnans\n",
    "\n",
    "contains_nan\n",
    "\n",
    "# We've successfully removed all NaN values!"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T15:35:55.504080700Z",
     "start_time": "2023-05-14T15:35:55.467577800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "outputs": [
    {
     "data": {
      "text/plain": "(   gender  age marital_status highest_qualification nationality ethnicity  \\\n 1    Male   38       Divorced      No Qualification     British     White   \n 2  Female   42         Single      No Qualification     British     White   \n 3    Male   40        Married                Degree     English     White   \n 4  Female   40        Married                Degree     English     White   \n 5  Female   39        Married          GCSE/O Level     British     White   \n \n        gross_income     region smoke  amt_weekends  amt_weekdays     type  \n 1    2,600 to 5,200  The North    No     16.410926     13.750594  Packets  \n 2       Under 2,600  The North   Yes     12.000000     12.000000  Packets  \n 3  28,600 to 36,400  The North    No     16.410926     13.750594  Packets  \n 4  10,400 to 15,600  The North    No     16.410926     13.750594  Packets  \n 5    2,600 to 5,200  The North    No     16.410926     13.750594  Packets  ,\n gender                    object\n age                        int64\n marital_status            object\n highest_qualification     object\n nationality               object\n ethnicity                 object\n gross_income              object\n region                    object\n smoke                     object\n amt_weekends             float64\n amt_weekdays             float64\n type                      object\n dtype: object,\n                age  amt_weekends  amt_weekdays\n count  1691.000000   1691.000000   1691.000000\n mean     49.836192     16.410926     13.750594\n std      18.736851      4.931838      4.680237\n min      16.000000      0.000000      0.000000\n 25%      34.000000     16.410926     13.750594\n 50%      48.000000     16.410926     13.750594\n 75%      65.500000     16.410926     13.750594\n max      97.000000     60.000000     55.000000)"
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, lets checkout if we have any odd standard deviations across our dataset\n",
    "\n",
    "\n",
    "imputed_smoking_df.head(), imputed_smoking_df.dtypes, imputed_smoking_df.describe()  # Doesn't look too bad at all, no insanely high standard deviations"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T15:35:55.541580700Z",
     "start_time": "2023-05-14T15:35:55.481080800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's look at how we can process the `gross_income` column, we can find a way to convert that to numerical, data, let's see what values that column contains, and come up with a method to parse it."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['2,600 to 5,200', 'Under 2,600', '28,600 to 36,400',\n       '10,400 to 15,600', '15,600 to 20,800', 'Above 36,400',\n       '5,200 to 10,400', 'Refused', '20,800 to 28,600', 'Unknown'],\n      dtype=object)"
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_smoking_df['gross_income'].unique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T15:35:55.549580600Z",
     "start_time": "2023-05-14T15:35:55.499080700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "outputs": [
    {
     "data": {
      "text/plain": "count    1.691000e+03\nmean     1.589914e-16\nstd      1.000296e+00\nmin     -1.048523e+00\n25%     -5.222177e-01\n50%     -1.011735e-01\n75%      3.198707e-01\nmax      3.267180e+00\nName: gross_income, dtype: float64"
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "gross_income_df = imputed_smoking_df.copy()\n",
    "\n",
    "\n",
    "def process_gross_income(income_amount: str) -> float:\n",
    "    income_amount = income_amount.replace(',', '')\n",
    "    if 'to' in income_amount:\n",
    "        [start, end] = income_amount.split(' to ')\n",
    "        return (int(end) + int(start)) / 2\n",
    "    elif 'Above' in income_amount:\n",
    "        above_amount = int(income_amount.split('Above ')[1])\n",
    "        return above_amount + (above_amount / 2)\n",
    "    elif 'Under' in income_amount:\n",
    "        under_amount = int(income_amount.split('Under ')[1])\n",
    "        return under_amount / 2\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def further_process(income_amount: float, mean: float) -> float:\n",
    "    if income_amount == 0:\n",
    "        return mean\n",
    "    return income_amount\n",
    "\n",
    "\n",
    "gross_income_df['gross_income'] = gross_income_df['gross_income'].map(lambda x: process_gross_income(x))\n",
    "\n",
    "gross_income_df['gross_income'] = gross_income_df['gross_income'].map(\n",
    "    lambda x: further_process(x, float(np.mean(gross_income_df['gross_income']))))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "gross_income_df['gross_income'] = scaler.fit_transform(gross_income_df[['gross_income']])\n",
    "\n",
    "imputed_smoking_df['gross_income'] = gross_income_df['gross_income']\n",
    "\n",
    "gross_income_df['gross_income'].describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T15:35:55.605096500Z",
     "start_time": "2023-05-14T15:35:55.526080700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We've now processed the gross income column, and successfully converted it to numerical data instead of categorical data. Now we must decide which column we want to preprocess next, let's observe the columns available to us right now."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "outputs": [
    {
     "data": {
      "text/plain": "gender                    object\nage                        int64\nmarital_status            object\nhighest_qualification     object\nnationality               object\nethnicity                 object\ngross_income             float64\nregion                    object\nsmoke                     object\namt_weekends             float64\namt_weekdays             float64\ntype                      object\ndtype: object"
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gross_income_df.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T15:35:55.634571Z",
     "start_time": "2023-05-14T15:35:55.605596800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can try to tackle the region column now, that is strictly categorical data, there is no way we can interpret it as numerical (in the case of gross income, we can interpret above 59000 as some number, but for example with region we can interpret region x as 0, y as 1, z as 2, and so on."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "outputs": [
    {
     "data": {
      "text/plain": "   gender  age marital_status highest_qualification nationality ethnicity  \\\n1    Male   38       Divorced      No Qualification     British     White   \n2  Female   42         Single      No Qualification     British     White   \n3    Male   40        Married                Degree     English     White   \n4  Female   40        Married                Degree     English     White   \n5  Female   39        Married          GCSE/O Level     British     White   \n\n   gross_income smoke  amt_weekends  amt_weekdays     type  \\\n1     -0.838001    No     16.410926     13.750594  Packets   \n2     -1.048523   Yes     12.000000     12.000000  Packets   \n3      1.477742    No     16.410926     13.750594  Packets   \n4     -0.101173    No     16.410926     13.750594  Packets   \n5     -0.838001    No     16.410926     13.750594  Packets   \n\n   region_Midlands & East Anglia  region_Scotland  region_South East  \\\n1                              0                0                  0   \n2                              0                0                  0   \n3                              0                0                  0   \n4                              0                0                  0   \n5                              0                0                  0   \n\n   region_South West  region_The North  region_Wales  \n1                  0                 1             0  \n2                  0                 1             0  \n3                  0                 1             0  \n4                  0                 1             0  \n5                  0                 1             0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gender</th>\n      <th>age</th>\n      <th>marital_status</th>\n      <th>highest_qualification</th>\n      <th>nationality</th>\n      <th>ethnicity</th>\n      <th>gross_income</th>\n      <th>smoke</th>\n      <th>amt_weekends</th>\n      <th>amt_weekdays</th>\n      <th>type</th>\n      <th>region_Midlands &amp; East Anglia</th>\n      <th>region_Scotland</th>\n      <th>region_South East</th>\n      <th>region_South West</th>\n      <th>region_The North</th>\n      <th>region_Wales</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>Male</td>\n      <td>38</td>\n      <td>Divorced</td>\n      <td>No Qualification</td>\n      <td>British</td>\n      <td>White</td>\n      <td>-0.838001</td>\n      <td>No</td>\n      <td>16.410926</td>\n      <td>13.750594</td>\n      <td>Packets</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Female</td>\n      <td>42</td>\n      <td>Single</td>\n      <td>No Qualification</td>\n      <td>British</td>\n      <td>White</td>\n      <td>-1.048523</td>\n      <td>Yes</td>\n      <td>12.000000</td>\n      <td>12.000000</td>\n      <td>Packets</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Male</td>\n      <td>40</td>\n      <td>Married</td>\n      <td>Degree</td>\n      <td>English</td>\n      <td>White</td>\n      <td>1.477742</td>\n      <td>No</td>\n      <td>16.410926</td>\n      <td>13.750594</td>\n      <td>Packets</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Female</td>\n      <td>40</td>\n      <td>Married</td>\n      <td>Degree</td>\n      <td>English</td>\n      <td>White</td>\n      <td>-0.101173</td>\n      <td>No</td>\n      <td>16.410926</td>\n      <td>13.750594</td>\n      <td>Packets</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Female</td>\n      <td>39</td>\n      <td>Married</td>\n      <td>GCSE/O Level</td>\n      <td>British</td>\n      <td>White</td>\n      <td>-0.838001</td>\n      <td>No</td>\n      <td>16.410926</td>\n      <td>13.750594</td>\n      <td>Packets</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# One hot encoding the categorical values of the region column, and creating a new dataframe from it\n",
    "dummies = pd.get_dummies(imputed_smoking_df, columns=['region'], drop_first=True)\n",
    "\n",
    "# copy the dataframe, which will have the `region` column removed and the one-hot encoded ones appended\n",
    "region_imputed_smoking_df = dummies.copy()\n",
    "\n",
    "region_imputed_smoking_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T15:35:55.652088200Z",
     "start_time": "2023-05-14T15:35:55.622571500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Alright! So far we have the region column one-hot encoded, resulting in a numerical representation of a categorical column, which allows our model to process it properly. We have a couple more categorical columns to process, like gender, marital_status, qualification, ethnicity, type, and nationality."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "outputs": [
    {
     "data": {
      "text/plain": "   age  gross_income  smoke  amt_weekends  amt_weekdays  \\\n1   38     -0.838001      0     16.410926     13.750594   \n2   42     -1.048523      1     12.000000     12.000000   \n3   40      1.477742      0     16.410926     13.750594   \n4   40     -0.101173      0     16.410926     13.750594   \n5   39     -0.838001      0     16.410926     13.750594   \n\n   region_Midlands & East Anglia  region_Scotland  region_South East  \\\n1                              0                0                  0   \n2                              0                0                  0   \n3                              0                0                  0   \n4                              0                0                  0   \n5                              0                0                  0   \n\n   region_South West  region_The North  ...  ethnicity_Black  \\\n1                  0                 1  ...                0   \n2                  0                 1  ...                0   \n3                  0                 1  ...                0   \n4                  0                 1  ...                0   \n5                  0                 1  ...                0   \n\n   ethnicity_Chinese  ethnicity_Mixed  ethnicity_Refused  ethnicity_Unknown  \\\n1                  0                0                  0                  0   \n2                  0                0                  0                  0   \n3                  0                0                  0                  0   \n4                  0                0                  0                  0   \n5                  0                0                  0                  0   \n\n   ethnicity_White  type_Both/Mainly Hand-Rolled  type_Both/Mainly Packets  \\\n1                1                             0                         0   \n2                1                             0                         0   \n3                1                             0                         0   \n4                1                             0                         0   \n5                1                             0                         0   \n\n   type_Hand-Rolled  type_Packets  \n1                 0             1  \n2                 0             1  \n3                 0             1  \n4                 0             1  \n5                 0             1  \n\n[5 rows x 45 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>gross_income</th>\n      <th>smoke</th>\n      <th>amt_weekends</th>\n      <th>amt_weekdays</th>\n      <th>region_Midlands &amp; East Anglia</th>\n      <th>region_Scotland</th>\n      <th>region_South East</th>\n      <th>region_South West</th>\n      <th>region_The North</th>\n      <th>...</th>\n      <th>ethnicity_Black</th>\n      <th>ethnicity_Chinese</th>\n      <th>ethnicity_Mixed</th>\n      <th>ethnicity_Refused</th>\n      <th>ethnicity_Unknown</th>\n      <th>ethnicity_White</th>\n      <th>type_Both/Mainly Hand-Rolled</th>\n      <th>type_Both/Mainly Packets</th>\n      <th>type_Hand-Rolled</th>\n      <th>type_Packets</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>38</td>\n      <td>-0.838001</td>\n      <td>0</td>\n      <td>16.410926</td>\n      <td>13.750594</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>42</td>\n      <td>-1.048523</td>\n      <td>1</td>\n      <td>12.000000</td>\n      <td>12.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>40</td>\n      <td>1.477742</td>\n      <td>0</td>\n      <td>16.410926</td>\n      <td>13.750594</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>40</td>\n      <td>-0.101173</td>\n      <td>0</td>\n      <td>16.410926</td>\n      <td>13.750594</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>39</td>\n      <td>-0.838001</td>\n      <td>0</td>\n      <td>16.410926</td>\n      <td>13.750594</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 45 columns</p>\n</div>"
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encoding all the remaining categorical columns, and placing it in the `gender_dummies` dataframe, now we create a new dataframe to process our data!\n",
    "gender_dummies = pd.get_dummies(region_imputed_smoking_df,\n",
    "                                columns=['gender', 'marital_status', 'highest_qualification', 'nationality',\n",
    "                                         'ethnicity', 'type'])\n",
    "\n",
    "gender_dummies['smoke'] = gender_dummies['smoke'].map(lambda x: 1 if x == 'Yes' else 0)\n",
    "\n",
    "gender_dummies.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T15:35:55.684588300Z",
     "start_time": "2023-05-14T15:35:55.653588700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "outputs": [
    {
     "data": {
      "text/plain": "               age  gross_income        smoke  amt_weekends  amt_weekdays  \\\ncount  1691.000000  1.691000e+03  1691.000000   1691.000000   1691.000000   \nmean     49.836192  1.589914e-16     0.248965     16.410926     13.750594   \nstd      18.736851  1.000296e+00     0.432541      4.931838      4.680237   \nmin      16.000000 -1.048523e+00     0.000000      0.000000      0.000000   \n25%      34.000000 -5.222177e-01     0.000000     16.410926     13.750594   \n50%      48.000000 -1.011735e-01     0.000000     16.410926     13.750594   \n75%      65.500000  3.198707e-01     0.000000     16.410926     13.750594   \nmax      97.000000  3.267180e+00     1.000000     60.000000     55.000000   \n\n       region_Midlands & East Anglia  region_Scotland  region_South East  \\\ncount                    1691.000000      1691.000000        1691.000000   \nmean                        0.261975         0.087522           0.149024   \nstd                         0.439839         0.282682           0.356218   \nmin                         0.000000         0.000000           0.000000   \n25%                         0.000000         0.000000           0.000000   \n50%                         0.000000         0.000000           0.000000   \n75%                         1.000000         0.000000           0.000000   \nmax                         1.000000         1.000000           1.000000   \n\n       region_South West  region_The North  ...  ethnicity_Black  \\\ncount        1691.000000       1691.000000  ...      1691.000000   \nmean            0.092844          0.251922  ...         0.020106   \nstd             0.290300          0.434245  ...         0.140406   \nmin             0.000000          0.000000  ...         0.000000   \n25%             0.000000          0.000000  ...         0.000000   \n50%             0.000000          0.000000  ...         0.000000   \n75%             0.000000          1.000000  ...         0.000000   \nmax             1.000000          1.000000  ...         1.000000   \n\n       ethnicity_Chinese  ethnicity_Mixed  ethnicity_Refused  \\\ncount        1691.000000      1691.000000        1691.000000   \nmean            0.015967         0.008279           0.007688   \nstd             0.125384         0.090639           0.087368   \nmin             0.000000         0.000000           0.000000   \n25%             0.000000         0.000000           0.000000   \n50%             0.000000         0.000000           0.000000   \n75%             0.000000         0.000000           0.000000   \nmax             1.000000         1.000000           1.000000   \n\n       ethnicity_Unknown  ethnicity_White  type_Both/Mainly Hand-Rolled  \\\ncount        1691.000000      1691.000000                   1691.000000   \nmean            0.001183         0.922531                      0.005914   \nstd             0.034381         0.267413                      0.076695   \nmin             0.000000         0.000000                      0.000000   \n25%             0.000000         1.000000                      0.000000   \n50%             0.000000         1.000000                      0.000000   \n75%             0.000000         1.000000                      0.000000   \nmax             1.000000         1.000000                      1.000000   \n\n       type_Both/Mainly Packets  type_Hand-Rolled  type_Packets  \ncount               1691.000000       1691.000000   1691.000000  \nmean                   0.024837          0.042578      0.926671  \nstd                    0.155675          0.201964      0.260754  \nmin                    0.000000          0.000000      0.000000  \n25%                    0.000000          0.000000      1.000000  \n50%                    0.000000          0.000000      1.000000  \n75%                    0.000000          0.000000      1.000000  \nmax                    1.000000          1.000000      1.000000  \n\n[8 rows x 45 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>gross_income</th>\n      <th>smoke</th>\n      <th>amt_weekends</th>\n      <th>amt_weekdays</th>\n      <th>region_Midlands &amp; East Anglia</th>\n      <th>region_Scotland</th>\n      <th>region_South East</th>\n      <th>region_South West</th>\n      <th>region_The North</th>\n      <th>...</th>\n      <th>ethnicity_Black</th>\n      <th>ethnicity_Chinese</th>\n      <th>ethnicity_Mixed</th>\n      <th>ethnicity_Refused</th>\n      <th>ethnicity_Unknown</th>\n      <th>ethnicity_White</th>\n      <th>type_Both/Mainly Hand-Rolled</th>\n      <th>type_Both/Mainly Packets</th>\n      <th>type_Hand-Rolled</th>\n      <th>type_Packets</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1691.000000</td>\n      <td>1.691000e+03</td>\n      <td>1691.000000</td>\n      <td>1691.000000</td>\n      <td>1691.000000</td>\n      <td>1691.000000</td>\n      <td>1691.000000</td>\n      <td>1691.000000</td>\n      <td>1691.000000</td>\n      <td>1691.000000</td>\n      <td>...</td>\n      <td>1691.000000</td>\n      <td>1691.000000</td>\n      <td>1691.000000</td>\n      <td>1691.000000</td>\n      <td>1691.000000</td>\n      <td>1691.000000</td>\n      <td>1691.000000</td>\n      <td>1691.000000</td>\n      <td>1691.000000</td>\n      <td>1691.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>49.836192</td>\n      <td>1.589914e-16</td>\n      <td>0.248965</td>\n      <td>16.410926</td>\n      <td>13.750594</td>\n      <td>0.261975</td>\n      <td>0.087522</td>\n      <td>0.149024</td>\n      <td>0.092844</td>\n      <td>0.251922</td>\n      <td>...</td>\n      <td>0.020106</td>\n      <td>0.015967</td>\n      <td>0.008279</td>\n      <td>0.007688</td>\n      <td>0.001183</td>\n      <td>0.922531</td>\n      <td>0.005914</td>\n      <td>0.024837</td>\n      <td>0.042578</td>\n      <td>0.926671</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>18.736851</td>\n      <td>1.000296e+00</td>\n      <td>0.432541</td>\n      <td>4.931838</td>\n      <td>4.680237</td>\n      <td>0.439839</td>\n      <td>0.282682</td>\n      <td>0.356218</td>\n      <td>0.290300</td>\n      <td>0.434245</td>\n      <td>...</td>\n      <td>0.140406</td>\n      <td>0.125384</td>\n      <td>0.090639</td>\n      <td>0.087368</td>\n      <td>0.034381</td>\n      <td>0.267413</td>\n      <td>0.076695</td>\n      <td>0.155675</td>\n      <td>0.201964</td>\n      <td>0.260754</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>16.000000</td>\n      <td>-1.048523e+00</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>34.000000</td>\n      <td>-5.222177e-01</td>\n      <td>0.000000</td>\n      <td>16.410926</td>\n      <td>13.750594</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>48.000000</td>\n      <td>-1.011735e-01</td>\n      <td>0.000000</td>\n      <td>16.410926</td>\n      <td>13.750594</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>65.500000</td>\n      <td>3.198707e-01</td>\n      <td>0.000000</td>\n      <td>16.410926</td>\n      <td>13.750594</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>97.000000</td>\n      <td>3.267180e+00</td>\n      <td>1.000000</td>\n      <td>60.000000</td>\n      <td>55.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 45 columns</p>\n</div>"
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalized_df = gender_dummies.copy()\n",
    "\n",
    "finalized_df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T15:35:55.760145100Z",
     "start_time": "2023-05-14T15:35:55.684088700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "outputs": [
    {
     "data": {
      "text/plain": "['age',\n 'gross_income',\n 'region_Midlands & East Anglia',\n 'region_Scotland',\n 'region_South East',\n 'region_South West',\n 'region_The North',\n 'region_Wales',\n 'gender_Female',\n 'gender_Male',\n 'marital_status_Divorced',\n 'marital_status_Married',\n 'marital_status_Separated',\n 'marital_status_Single',\n 'marital_status_Widowed',\n 'highest_qualification_A Levels',\n 'highest_qualification_Degree',\n 'highest_qualification_GCSE/CSE',\n 'highest_qualification_GCSE/O Level',\n 'highest_qualification_Higher/Sub Degree',\n 'highest_qualification_No Qualification',\n 'highest_qualification_ONC/BTEC',\n 'highest_qualification_Other/Sub Degree',\n 'nationality_British',\n 'nationality_English',\n 'nationality_Irish',\n 'nationality_Other',\n 'nationality_Refused',\n 'nationality_Scottish',\n 'nationality_Unknown',\n 'nationality_Welsh',\n 'ethnicity_Asian',\n 'ethnicity_Black',\n 'ethnicity_Chinese',\n 'ethnicity_Mixed',\n 'ethnicity_Refused',\n 'ethnicity_Unknown',\n 'ethnicity_White',\n 'type_Both/Mainly Hand-Rolled',\n 'type_Both/Mainly Packets',\n 'type_Hand-Rolled']"
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "mutual_info = mutual_info_classif(finalized_df.drop(columns=['smoke']), finalized_df['smoke'])\n",
    "\n",
    "cols = finalized_df.drop(columns=['smoke']).columns\n",
    "\n",
    "mutual_info_df = pd.DataFrame({cols[0]: [0]})\n",
    "\n",
    "for ind, each_column in enumerate(cols):\n",
    "    mutual_info_df[each_column] = mutual_info[ind]\n",
    "\n",
    "values = {}\n",
    "\n",
    "for each_value in mutual_info_df:\n",
    "    col_value = list(mutual_info_df[each_value])[0]\n",
    "    values[each_value] = col_value\n",
    "\n",
    "removal_values = []\n",
    "for each_key in values:\n",
    "    if values[each_key] < 0.09:\n",
    "        removal_values.append(each_key)\n",
    "\n",
    "removal_values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T15:35:56.101644900Z",
     "start_time": "2023-05-14T15:35:55.762644300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flyin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.8297872340425532, 0.8496621621621622)"
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "finalized_df_clone = finalized_df.copy()\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(finalized_df_clone.drop(columns=['smoke']),\n",
    "                                                    finalized_df_clone['smoke'], test_size=.35)\n",
    "\n",
    "log_model = LogisticRegression()\n",
    "\n",
    "log_model.fit(train_x, train_y)\n",
    "\n",
    "altered_df_clone = finalized_df_clone.copy()\n",
    "\n",
    "altered_df_clone.drop(columns=removal_values, inplace=True)\n",
    "\n",
    "altered_log_model = LogisticRegression()\n",
    "\n",
    "altered_train_x, altered_test_x, altered_train_y, altered_test_y = train_test_split(\n",
    "    altered_df_clone.drop(columns=['smoke']), altered_df_clone['smoke'])\n",
    "\n",
    "altered_log_model.fit(altered_train_x, altered_train_y)\n",
    "\n",
    "altered_log_model.score(altered_test_x, altered_test_y), log_model.score(test_x, test_y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T15:35:56.178151500Z",
     "start_time": "2023-05-14T15:35:56.101644900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "outputs": [
    {
     "data": {
      "text/plain": "(1.0,\n                0      1  accuracy  macro avg  weighted avg\n precision    1.0    1.0       1.0        1.0           1.0\n recall       1.0    1.0       1.0        1.0           1.0\n f1-score     1.0    1.0       1.0        1.0           1.0\n support    460.0  132.0       1.0      592.0         592.0)"
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Let's try it with a random forest!\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "random_forest_model = RandomForestClassifier()\n",
    "\n",
    "random_forest_model.fit(train_x, train_y)\n",
    "\n",
    "predictions = random_forest_model.predict(test_x)\n",
    "\n",
    "# Using a random forest classifier, we have reached a perfect model score, something is fishy though, perfect model scores may be a result of underfitting or overfitting.\n",
    "random_forest_model.score(test_x,\n",
    "                          test_y), pd.DataFrame(classification_report(test_y, predictions, output_dict=True))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T15:39:47.520276Z",
     "start_time": "2023-05-14T15:39:47.354079800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Wow! So we managed to score an insanely high score using our RandomForestClassification model, we managed to achieve a perfect score across the board. This was due to one-hot encoding all the categorical variables, and standardizing the continuous variables in the model, to achieve the most efficient dataset for our model to process. Overall, this was an interesting and enlightening foray into handling categorical variables, missing values, and different type of model performances in a dataset consisting of 90% categorical variables. I imputed the values properly, and cleaned up this dataset just right for the random forest to excell in predicting the test dataset properly. Going to pickle-ize this model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'smoking_rfc.pkl'\n",
    "pickle.dump(random_forest_model, open(filename, 'wb'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T15:43:46.686971600Z",
     "start_time": "2023-05-14T15:43:46.667030Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
