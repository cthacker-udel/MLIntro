{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to measure which ketchup is the greatest! We will be pulling in data from the ketchup data, and finding out a target variable to select from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4956, 7)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ketchup_data = pd.read_csv('./Ketchup.csv', index_col=0)\n",
    "\n",
    "ketchup_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Ketchup.hid', 'Ketchup.id', 'Ketchup.choice', 'price.heinz',\n",
       "       'price.hunts', 'price.delmonte', 'price.stb'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ketchup_data.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our target variable has been selected to be `Ketchup.choice`, which we will plug into a few different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First we must do some data cleaning, checking if any of the columns contain null values\n",
    "\n",
    "null_columns = [col for col in ketchup_data.columns if ketchup_data[col].hasnans]\n",
    "\n",
    "null_columns # the data is completely clean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now we must separate the columns into integer and categorical columns to plug into our pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ketchup_data.copy()\n",
    "y = X.pop('Ketchup.choice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ketchup.hid',\n",
       " 'Ketchup.id',\n",
       " 'price.heinz',\n",
       " 'price.hunts',\n",
       " 'price.delmonte',\n",
       " 'price.stb']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_columns = [col for col in ketchup_data.columns if ketchup_data[col].dtype in ['int64', 'float64']]\n",
    "\n",
    "numerical_columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### I don't think we need the ids in this equation, as they don't have any feature value to contribute to the prediction, the only features the consumer is knowledgeable about is the price of heinz, the price of hunts, the price of delmonte, and the price of stb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['price.heinz', 'price.hunts', 'price.delmonte', 'price.stb']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_x = X.drop(columns=['Ketchup.hid', 'Ketchup.id'])\n",
    "\n",
    "\n",
    "modified_numerical_columns = [col for col in modified_x if modified_x[col].dtype in ['int64', 'float64']]\n",
    "\n",
    "modified_numerical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_categorical_columns = [col for col in modified_x if modified_x[col].dtype == 'object']\n",
    "\n",
    "modified_categorical_columns # which there are none?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2472264511242455"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create the pipeline\n",
    "from sklearn.pipeline import Pipeline # the pipeline to make the data modeling process easier and cleaner\n",
    "from sklearn.ensemble import RandomForestRegressor # the model we will be using with the data\n",
    "from sklearn.model_selection import train_test_split # split the data into sections\n",
    "from sklearn.metrics import mean_absolute_error # analyze the prediction score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "y_df = pd.DataFrame(y)\n",
    "\n",
    "y_encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "encoded_y = pd.DataFrame(y_encoder.fit_transform(y_df))\n",
    "\n",
    "new_y = encoded_y\n",
    "\n",
    "pipeline = Pipeline(steps=[('model', RandomForestRegressor())])\n",
    "\n",
    "train_x, validation_x, train_y, validation_y = train_test_split(modified_x, new_y)\n",
    "\n",
    "pipeline.fit(train_x, train_y)\n",
    "\n",
    "mean_absolute_error(pipeline.predict(validation_x), validation_y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As you can see, with our one-hot-encoding method, since we have to avoid imputation entirely (as there are no NaN values), we can focus on encoding the categorical value, the Ketchup.choice, which happens to be our target variable. Encoding it using One-Hot Encoding yields a fantastic result of almost exact precision, but slightly less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      price.heinz  price.hunts  price.delmonte  price.stb\n",
      "1902         1.39         1.36            1.49       0.95\n",
      "222          1.46         1.43            1.45       0.99\n",
      "1830         0.79         1.43            1.45       0.99\n",
      "326          1.39         0.79            1.39       0.95\n",
      "4684         1.46         1.43            0.99       0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\flyin\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6382125649968083"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Let's try ordinal encoding instead\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "o_encoded_y = pd.DataFrame(encoder.fit_transform(y_df))\n",
    "\n",
    "pipelinev2 = Pipeline(steps=[('encode', OrdinalEncoder()), ('model', RandomForestRegressor())])\n",
    "\n",
    "o_e_train_x, o_e_validation_x, o_e_train_y, o_e_validation_y = train_test_split(modified_x, o_encoded_y)\n",
    "\n",
    "pipelinev2.fit(o_e_train_x, o_e_train_y)\n",
    "\n",
    "print(o_e_validation_x.head())\n",
    "\n",
    "mean_absolute_error(pipelinev2.predict(o_e_validation_x), o_e_validation_y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### As you can see, the OneHotEncoding method is more viable then the OrdinalEncoding method, however just slightly, we can try passing it into a neural network instead, using Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.5301726231647654"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "ketchup_nn = keras.Sequential(layers=[layers.Dense(units=512, input_shape=[4]), layers.Dense(units=512, activation='relu'), layers.Dense(units=512, activation='relu'), layers.Dense(units=1)])\n",
    "\n",
    "predictions = ketchup_nn.predict(o_e_validation_x)\n",
    "\n",
    "mean_absolute_error(predictions, o_e_validation_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training_model = keras.Sequential([\n",
    "    layers.Dense(units=1, input_shape=[3])\n",
    "])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
